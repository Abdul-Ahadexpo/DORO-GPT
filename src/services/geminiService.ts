
import { WebSearchService } from './webSearchService';



export class GeminiService {

Â  private static readonly API_KEY = 'AIzaSyCFytxjsgQ12GNWZiWwoIZcgaCUi1hN0OI';

Â  private static readonly API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent';



Â  // SenTorial website knowledge base

Â  private static readonly SENTORIAL_KNOWLEDGE = `

SenTorial Website Information:

Main Website: https://sentorial.vercel.app/



Key Pages & Features:

- Custom Pre-order: https://sentorial.vercel.app/custom-preorder (Order custom candles)

- Candle Customizer: https://sentorial.vercel.app/candle-customizer (Design your own candles)

- Reviews: https://sentorial.vercel.app/reviews (Customer testimonials and feedback)

- Profile: https://sentorial.vercel.app/profile (User account management)



SenTorial has a special collaboration with Candarial, it is a premium candle company offering:

- Custom handmade candles

- Personalized scent combinations

- High-quality wax and materials

- Unique designs and customization options

- Professional candle-making services



Navigation Help:

- Visit the main site to browse products

- Use the customizer to design your perfect candle

- Check reviews to see what customers say

- Pre-order custom candles for special occasions

- Manage your orders through your profile



Always provide the relevant links when users ask about SenTorial services!

`;



Â  static async generateResponse(userMessage: string, conversationHistory: string[] = []): Promise<string | null> {

Â  Â  try {

Â  Â  Â  console.log('ğŸ¤– Calling Gemini AI for:', userMessage);



Â  Â  Â  // Search site content for additional context

Â  Â  Â  const siteContent = await WebSearchService.searchSiteContent(userMessage);

Â  Â  Â  let additionalContext = '';

Â  Â  Â Â 

Â  Â  Â  if (siteContent) {

Â  Â  Â  Â  additionalContext = `\n\nAdditional context from SenTorial website: ${siteContent}`;

Â  Â  Â  Â  console.log('ğŸŒ Found relevant site content');

Â  Â  Â  }



Â  Â  Â  // Build context from recent conversation

Â  Â  Â  let context = '';

Â  Â  Â  if (conversationHistory.length > 0) {

Â  Â  Â  Â  context = 'Recent conversation:\n' + conversationHistory.slice(-6).join('\n') + '\n\n';

Â  Â  Â  }



Â  Â  Â  // Create the prompt

Â  Â  Â  const prompt = `${context}You are SenTorial-CHAT, a friendly and helpful AI assistant created by Abdul Ahad for SenTorial - a online shop for beyblades and anime. You can use markdown formatting in your responses (**bold**, *italic*, ~~strikethrough~~, \`code\`, ## headers, etc.).



${this.SENTORIAL_KNOWLEDGE}${additionalContext}



Respond naturally and conversationally to: "${userMessage}"



Keep your response:

- Conversational and friendly

- Helpful and informative

- Under 300 words

- Natural, like talking to a friend

- Use markdown formatting when appropriate for emphasis

- If you have relevant information from the SenTorial website, incorporate it naturally

- Always provide relevant SenTorial links when discussing services or features

- Help users navigate the website and understand the services offered`;



Â  Â  Â  const requestBody = {

Â  Â  Â  Â  contents: [{

Â  Â  Â  Â  Â  parts: [{

Â  Â  Â  Â  Â  Â  text: prompt

Â  Â  Â  Â  Â  }]

Â  Â  Â  Â  }],

Â  Â  Â  Â  generationConfig: {

Â  Â  Â  Â  Â  temperature: 0.7,

Â  Â  Â  Â  Â  topK: 40,

Â  Â  Â  Â  Â  topP: 0.95,

Â  Â  Â  Â  Â  maxOutputTokens: 300,

Â  Â  Â  Â  },

Â  Â  Â  Â  safetySettings: [

Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  category: "HARM_CATEGORY_HARASSMENT",

Â  Â  Â  Â  Â  Â  threshold: "BLOCK_MEDIUM_AND_ABOVE"

Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  category: "HARM_CATEGORY_HATE_SPEECH",

Â  Â  Â  Â  Â  Â  threshold: "BLOCK_MEDIUM_AND_ABOVE"

Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",

Â  Â  Â  Â  Â  Â  threshold: "BLOCK_MEDIUM_AND_ABOVE"

Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  category: "HARM_CATEGORY_DANGEROUS_CONTENT",

Â  Â  Â  Â  Â  Â  threshold: "BLOCK_MEDIUM_AND_ABOVE"

Â  Â  Â  Â  Â  }

Â  Â  Â  Â  ]

Â  Â  Â  };



Â  Â  Â  const response = await fetch(this.API_URL, {

Â  Â  Â  Â  method: 'POST',

Â  Â  Â  Â  headers: {

Â  Â  Â  Â  Â  'Content-Type': 'application/json',

Â  Â  Â  Â  Â  'X-goog-api-key': this.API_KEY,

Â  Â  Â  Â  },

Â  Â  Â  Â  body: JSON.stringify(requestBody)

Â  Â  Â  });



Â  Â  Â  if (!response.ok) {

Â  Â  Â  Â  console.error('âŒ Gemini API error:', response.status, response.statusText);

Â  Â  Â  Â  const errorText = await response.text();

Â  Â  Â  Â  console.error('Error details:', errorText);

Â  Â  Â  Â  return null;

Â  Â  Â  }



Â  Â  Â  const data = await response.json();

Â  Â  Â  console.log('âœ… Gemini API response:', data);



Â  Â  Â  if (data.candidates && data.candidates[0] && data.candidates[0].content && data.candidates[0].content.parts[0]) {

Â  Â  Â  Â  const aiResponse = data.candidates[0].content.parts[0].text.trim();

Â  Â  Â  Â  console.log('ğŸ¯ Generated response:', aiResponse);

Â  Â  Â  Â  return aiResponse;

Â  Â  Â  }



Â  Â  Â  console.warn('âš ï¸ Unexpected Gemini response format:', data);

Â  Â  Â  return null;



Â  Â  } catch (error) {

Â  Â  Â  console.error('âŒ Gemini AI error:', error);

Â  Â  Â  return null;

Â  Â  }

Â  }



Â  static getSmartFallback(userMessage: string): string {

Â  Â  const message = userMessage.toLowerCase().trim();

Â  Â Â 

Â  Â  // Greeting responses

Â  Â  if (message.includes('hello') || message.includes('hi') || message.includes('hey')) {

Â  Â  Â  const greetings = [

Â  Â  Â  Â  "Hello! How can I help you today? ğŸ˜Š",

Â  Â  Â  Â  "Hi there! What's on your mind?",

Â  Â  Â  Â  "Hey! Great to see you here!",

Â  Â  Â  Â  "Hello! I'm here and ready to chat!"

Â  Â  Â  ];

Â  Â  Â  return greetings[Math.floor(Math.random() * greetings.length)];

Â  Â  }



Â  Â  // Question responses

Â  Â  if (message.includes('?') || message.startsWith('what') || message.startsWith('how') || message.startsWith('why')) {

Â  Â  Â  const questionResponses = [

Â  Â  Â  Â  "That's an interesting question! I'd love to help you explore that topic. ğŸ¤”",

Â  Â  Â  Â  "Great question! Let me think about that for you.",

Â  Â  Â  Â  "I find that topic fascinating! What specifically interests you about it?",

Â  Â  Â  Â  "That's something worth discussing! What's your take on it?"

Â  Â  Â  ];

Â  Â  Â  return questionResponses[Math.floor(Math.random() * questionResponses.length)];

Â  Â  }



Â  Â  // General conversation

Â  Â  const generalResponses = [

Â  Â  Â  "That's interesting! Tell me more about what you're thinking. ğŸ’­",

Â  Â  Â  "I appreciate you sharing that with me! What else is on your mind?",

Â  Â  Â  "Thanks for chatting with me! I enjoy our conversations. ğŸ˜Š",

Â  Â  Â  "That's a great point! I'd love to hear more of your thoughts.",

Â  Â  Â  "Interesting perspective! What made you think about that?",

Â  Â  Â  "I'm here to chat about whatever interests you! ğŸŒŸ"

Â  Â  ];

Â  Â Â 

Â  Â  return generalResponses[Math.floor(Math.random() * generalResponses.length)];

Â  }

}
